{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       id                                             lyrics  \\\n",
      "0  1FAmKoufyAXMfzPPs9bsjA  i tied my bandana took my pack from the floor ...   \n",
      "1  3QvPEv8XjHa73iYhaienWw  i want to live on the moon never see a human a...   \n",
      "2  5VPFATm85G3P04Q5g8yxqr  bitch you know you can t parallel park anyway ...   \n",
      "3  7J2jCftItt7htcOUdcMnpt  graceless falling slipping in the cold with no...   \n",
      "4  4cBPzVIbDIQx0LIyauFAy0  madame morse estate stood five hundred years p...   \n",
      "\n",
      "       artist_name most_common_genre  \\\n",
      "0  Waylon Jennings           country   \n",
      "1   Phantom Planet              rock   \n",
      "2    Isaiah Rashad           hip-hop   \n",
      "3     Matt Pond PA             indie   \n",
      "4       Ariel Pink               pop   \n",
      "\n",
      "                                          genre_list  \n",
      "0  ['country', 'country', 'rock', 'outlaw', 'coun...  \n",
      "1                                    ['pop', 'rock']  \n",
      "2  ['hip-hop', 'rap', 'tennessee', 'hip-hop', 'un...  \n",
      "3                                ['philly', 'indie']  \n",
      "4  ['art', 'pop', 'chillwave', 'dream', 'pop', 'e...  \n"
     ]
    }
   ],
   "source": [
    "# Load train and test data\n",
    "train_data = pd.read_csv(\"../data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"../data/test_data.csv\")\n",
    "\n",
    "print(train_data.head())\n",
    "\n",
    "# Split train and test data into features and targets\n",
    "train_features = train_data[\"lyrics\"]\n",
    "train_targets = train_data[\"most_common_genre\"]\n",
    "\n",
    "test_features = test_data[\"lyrics\"]\n",
    "test_targets = test_data[\"most_common_genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19052, 57574) (4763, 57574)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors_train = vectorizer.fit_transform(train_features)\n",
    "vectors_test = vectorizer.transform(test_features)\n",
    "print(vectors_train.shape, vectors_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3652600973786819 0.431660718034852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(vectors_train, train_targets)\n",
    "pred = clf.predict(vectors_test)\n",
    "print(metrics.f1_score(test_targets, pred, average='macro'),\n",
    "     metrics.accuracy_score(test_targets, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: we your it of me my and to you the\n",
      "rock: she in my that me it to and you the\n",
      "hip-hop: like me that in my it to and you the\n",
      "indie: your we in me my it to and the you\n",
      "pop: we my in it me and of to you the\n",
      "rap: that oh we my to it me and the you\n",
      "christian: me my of in we it and to you the\n",
      "metal: in that me nigga to and my it you the\n",
      "punk: your of in my me it to and the you\n",
      "soul: my it oh and baby to love the me you\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "     feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "     for i, category in enumerate(categories):\n",
    "         top10 = np.argsort(classifier.feature_log_prob_[i])[-10:]\n",
    "         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "        \n",
    "show_top10(clf,vectorizer, train_targets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40328385016391743 0.4400587864791098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC()\n",
    "\n",
    "clf.fit(vectors_train, train_targets)\n",
    "pred = clf.predict(vectors_test)\n",
    "print(metrics.f1_score(test_targets, pred, average='macro'), \n",
    "metrics.accuracy_score(test_targets, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19052, 10326874) (4763, 10326874)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,5))\n",
    "vectors_train = vectorizer.fit_transform(train_features)\n",
    "vectors_test = vectorizer.transform(test_features)\n",
    "print(vectors_train.shape, vectors_test.shape)\n",
    "\n",
    "clf = LinearSVC()\n",
    "\n",
    "clf.fit(vectors_train, train_targets)\n",
    "pred = clf.predict(vectors_test)\n",
    "print(metrics.f1_score(test_targets, pred, average='macro'), \n",
    "metrics.accuracy_score(test_targets, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19052, 6320460) (4763, 6320460)\n",
      "0.3990220103637426 0.44866680663447406\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,5), stop_words='english')\n",
    "vectors_train = vectorizer.fit_transform(train_features)\n",
    "vectors_test = vectorizer.transform(test_features)\n",
    "print(vectors_train.shape, vectors_test.shape)\n",
    "\n",
    "clf = LinearSVC()\n",
    "\n",
    "clf.fit(vectors_train, train_targets)\n",
    "pred = clf.predict(vectors_test)\n",
    "print(metrics.f1_score(test_targets, pred, average='macro'), \n",
    "metrics.accuracy_score(test_targets, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4136638606358827 0.46609279865630904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "context_features = FeatureUnion(\n",
    "        transformer_list=[\n",
    "            ('word1', TfidfVectorizer(ngram_range=(1, 7),lowercase=True)),\n",
    "            ('word2', TfidfVectorizer(ngram_range=(1, 3),lowercase=True)),\n",
    "            ('word3', TfidfVectorizer(ngram_range=(1, 5),lowercase=False)),\n",
    "            ('char', TfidfVectorizer(lowercase=False, analyzer='char', ngram_range=(2, 3)))])\n",
    "\n",
    "clf = make_pipeline(context_features, LinearSVC())\n",
    "clf.fit(train_features, train_targets)\n",
    "pred = clf.predict(test_features)\n",
    "\n",
    "print(metrics.f1_score(test_targets, pred, average='macro'), \n",
    "metrics.accuracy_score(test_targets, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46609279865630904"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_features, test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npr-mc1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
