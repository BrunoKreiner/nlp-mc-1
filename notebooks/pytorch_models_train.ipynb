{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Define your PyTorch models here\n",
    "models = [MyModel1(), MyModel2(), MyModel3()]\n",
    "\n",
    "# Define your loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create a list to store the optimizer for each model\n",
    "optimizers = [optim.Adam(model.parameters(), lr=0.001) for model in models]\n",
    "\n",
    "# Create a dataframe to store the model accuracy, train loss, and test loss\n",
    "df = pd.DataFrame(columns=['model', 'epoch', 'accuracy', 'train_loss', 'test_loss'])\n",
    "\n",
    "# Train your models\n",
    "num_epochs = 10\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train the model\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_dataloader:\n",
    "            optimizers[model_idx].zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizers[model_idx].step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                outputs = model(inputs)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                total_correct += (predictions == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "        accuracy = total_correct / total_samples\n",
    "        train_loss = train_loss / len(train_dataloader.dataset)\n",
    "        test_loss = test_loss / len(test_dataloader.dataset)\n",
    "        print(f\"Model {model_idx+1} - Epoch {epoch+1} Accuracy: {accuracy:.4f} Train Loss: {train_loss:.4f} Test Loss: {test_loss:.4f}\")\n",
    "        \n",
    "        # Add the accuracy, train loss, and test loss to the dataframe\n",
    "        df = df.append({'model': f'model{model_idx+1}', 'epoch': epoch+1, 'accuracy': accuracy, 'train_loss': train_loss, 'test_loss': test_loss}, ignore_index=True)\n",
    "\n",
    "    # Save the dataframe as a CSV file for each model\n",
    "    df.to_csv(f'model{model_idx+1}_accuracy.csv', index=False)\n",
    "    df = df.iloc[0:0]\n",
    "\n",
    "    # Generate the confusion matrix for the model on the test data\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(f\"Model {model_idx+1} Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"Classification Report:\")\n",
    "    print(report)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
